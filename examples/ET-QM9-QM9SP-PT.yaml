activation: silu
aggr: add
atom_filter: -1
attn_activation: silu
batch_size: 128
coord_files: null
cutoff_lower: 0.0
cutoff_upper: 5.0
dataset: QM9SP
dataset_arg: alpha
dataset_root: ../data/qm9sp
derivative: false
distance_influence: both
distributed_backend: ddp
early_stopping_patience: 150
ema_alpha_dy: 1.0
ema_alpha_y: 1.0
embed_files: null
embedding_dimension: 256
energy_files: null
energy_weight: 0.0
force_files: null
force_weight: 0.0
inference_batch_size: 70
load_model: null
log_dir: experiments/
lr: 0.0004
lr_schedule: cosine
lr_factor: 0.8
lr_min: 1.0e-07
lr_patience: 15
lr_warmup_steps: 10000
lr_cosine_length: 400000
max_num_neighbors: 32
max_z: 100
model: equivariant-transformer
neighbor_embedding: true
ngpus: 1
num_epochs: 3000
num_steps: 400000
num_heads: 8
num_layers: 8
num_nodes: 1
num_rbf: 64
num_workers: 6
output_model: Scalar
precision: 32
prior_model: null
rbf_type: expnorm
redirect: false
reduce_op: add
save_interval: 10
splits: null
standardize: false
test_interval: 10
test_size: null
train_size: 110000
trainable_rbf: false
val_size: 10000
weight_decay: 0.0
output_model_noise: VectorOutput
position_noise_scale: 0.04
denoising_weight: 1.0
denoising_only: true
layernorm_on_vec: null
wandb_notes: ""
job_id: auto

output_model_spec: null
output_model_mol: null
uv_model: null # SpecFormer
input_data_norm_type: log10
contrastive_weight: 0.0

# SpecFormer [uv, ir, raman]
patch_len: [20,50,50]
stride: [10,25,25]
reconstruct_weight: 0.0
mask_ratios: [0.1,0.1,0.1]

reduce_lr_when_bad: false